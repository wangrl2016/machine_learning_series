<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>深度学习综合指南</title>
    <!-- 引入 Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        body {
            scroll-behavior: smooth; /* 平滑滚动 */
        }
        .sidebar {
            position: sticky;
            top: 0;
            height: 100vh;
            overflow-y: auto;
            background-color: #fff;
            color: #000;
            border-right: 1px solid #ddd;
        }
        .sidebar a {
            color: #007bff;
            text-decoration: none;
        }
        .sidebar a:hover {
            color: #0056b3;
        }
        .child-chapters {
            list-style-type: none;
            padding: 0;
            margin: 0;
        }
        .child-chapters li:hover {
            background-color: #e9ecef;
            transform: translateX(5px);
            box-shadow: 0px 2px 5px rgba(0, 0, 0, 0.1);
        }
        .content-section {
            padding-top: 50px;
            margin-bottom: 50px;
        }
        h1 {
            color: #2c3e50;
            font-size: 3em;
            text-align: center;
            margin-top: 20px;
            margin-bottom: 40px;
            font-weight: bold;
            letter-spacing: 2px;
            border-bottom: 6px solid #2c3e50;
            padding-bottom: 20px;
        }
        h2, h3, h4 {
            margin-top: 30px;
            margin-bottom: 15px;
        }
        .content-section > h2 {
            color: #2980b9; /* 深蓝色 */
            font-size: 2em;
            border-bottom: 4px solid #2980b9;
            padding-bottom: 15px;
            margin-bottom: 50px;
        }
        .content-section h3 {
            color: #e74c3c; /* 红色 */
            font-size: 1.5em;
            border-left: 6px solid #e74c3c;
            padding-left: 15px;
            margin-top: 40px;
            margin-bottom: 25px;
        }
        .content-section h4 {
            color: #8e44ad; /* 紫色 */
            font-size: 1em;
            margin-top: 20px;
            margin-bottom: 12px;
            border-left: 5px solid #8e44ad;
            padding-left: 12px;
        }
        p {
            margin: 20px 0;
            font-size: 1.1em;
            text-indent: 2em;
        }
        .right-sidebar {
            position: sticky;
            top: 0;
            height: 100vh;
            overflow-y: auto;
            padding: 20px;
            background-color: #f8f9fa;
            border-left: 1px solid #ddd;
        }
        .right-sidebar a {
            color: #343a40;
            text-decoration: none;
        }
        .right-sidebar a:hover {
            text-decoration: underline;
        }
        .right-sidebar .active {
            font-weight: bold;
            color: #007bff;
        }
        ul {
            list-style: none;
            padding-left: 20px;
            margin: 10px 0;
        }
        .with-bullets {
            list-style: disc;
            padding-left: 10px;
            margin: 10px 0 10px 20px;
        }
        ul li {
            margin: 4px 0;
            color: #34495e;;
        }
        li .title {
            font-weight: bold;
            color: #2c3e50;
            font-size: 16px;
            margin-bottom: 6px;
        }
        li p {
            color: #34495e;
            font-size: 16px;
        }
        a {
            text-decoration: underline;
            text-underline-offset: 8px;
            color: #3498db;
        }
        /* 移动端样式（只在屏幕宽度 < 1024 px 时生效 */
        @media screen and (max-width: 1024px) {
            .sidebar, .right-sidebar {
                display: none;
            }
            .content {
                margin: 0;
                padding: 10px;
                width: 100%;
            }
        }
    </style>
</head>
<body>
    <div class="container-fluid">
        <div class="row">
            <!-- 左侧目录 -->
            <nav class="col-md-2 bg-light sidebar">
                <h5 class="p-3"><a href="../index.html">主页</a></h5>
                <ul class="nav flex-column">
                    <li class="nav-item">
                        <a class="nav-link" href="#section1" onclick="toggleChildChapters(event, 'chapter1')">01 认识机器学习：绘制直线</a>
                        <ul id="chapter1" class="child-chapters" style="display: none;">
                            <li><a class="nav-link" href="#section1-sub1">1.1 函数基础</a></li>
                            <li><a class="nav-link" href="#section1-sub2">1.2 NumPy 介绍</a></li>
                            <li><a class="nav-link" href="#section1-sub3">1.3 常见函数</a></li>
                            <li><a class="nav-link" heaf="#section1-sub4">1.4 传统方程求解</a></li>
                            <li><a class="nav-link" heaf="#section1-sub5">1.5 机器学习求解</a></li>
                        </ul>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#section2" onclick="toggleChildChapters(event, 'chapter2')">02 深度学习原理</a>
                        <ul id="chapter2" class="child-chapters" style="display: none;">
                            <li><a class="nav-link" href="#section2-sub1">2.1 什么是机器学习</a></li>
                            <li><a class="nav-link" href="#section2-sub2">2.2 人工神经网络</a></li>
                            <li><a class="nav-link" href="#section2-sub3">2.3 线性代数</a></li>
                            <li><a class="nav-link" heaf="#section2-sub4">2.4 数据表示</a></li>
                            <li><a class="nav-link" heaf="#section2-sub5">2.5 数据操作</a></li>
                            <li><a class="nav-link" heaf="#section2-sub6">2.6 常见微型数据集</a></li>
                        </ul>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#section3" onclick="toggleChildChapters(event, 'chapter3')">03 分类问题：Keras 求解</a>
                        <ul id="chapter3" class="child-chapters" style="display: none;">
                            <li><a class="nav-link" href="#section3-sub1">3.1 统计学入门</a></li>
                            <li><a class="nav-link" href="#section3-sub2">3.2 二分类问题</a></li>
                            <li><a class="nav-link" href="#section3-sub3">3.3 Keras 快速入门</a></li>
                            <li><a class="nav-link" heaf="#section3-sub4">3.4 图片分类</a></li>
                            <li><a class="nav-link" heaf="#section3-sub5">3.5 其它分类问题</a></li>
                        </ul>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#section4" onclick="toggleChildChapters(event, 'chapter4')">04 详解反向传播算法</a>
                        <ul id="chapter4" class="child-chapters" style="display: none;">
                            <li><a class="nav-link" href="#section4-sub1">4.1 导数</a></li>
                            <li><a class="nav-link" href="#section4-sub2">4.2 激活函数</a></li>
                            <li><a class="nav-link" href="#section4-sub3">4.3 损失函数</a></li>
                            <li><a class="nav-link" heaf="#section4-sub4">4.4 梯度下降</a></li>
                            <li><a class="nav-link" heaf="#section4-sub5">4.5 手写神经网络</a></li>
                            <li><a class="nav-link" heaf="#section4-sub6">4.6 绘制曲线</a></li>
                            <li><a class="nav-link" heaf="#section4-sub7">4.7 坐标点分类</a></li>
                        </ul>
                    </li>
                    <li class="nav-item"><a class="nav-link" href="#section5">05 张量与自动微分</a></li>
                    <li class="nav-item"><a class="nav-link" href="#section6">06 训练神经网络</a></li>

                    <li class="nav-item">
                        <a class="nav-link" href="#section7" onclick="toggleChildChapters(event, 'chapter7')">07 卷积神经网络</a>
                        <ul id="chapter7" class="child-chapters" style="display: none;">
                            <li><a class="nav-link" href="#section7-sub1">7.1 认识卷积网络</a></li>
                            <li><a class="nav-link" href="#section7-sub2">7.2 手写卷积网络</a></li>
                            <li><a class="nav-link" href="#section7-sub3">7.3 AlexNet 论文</a></li>
                            <li><a class="nav-link" href="#section7-sub4">7.4 U-Net 论文</a></li>
                            <li><a class="nav-link" href="#section7-sub5">7.5 ResNet 论文</a></li>
                        </ul>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#section8" onclick="toggleChildChapters(event, 'chapter8')">08 循环神经网络</a>
                        <ul id="chapter8" class="child-chapters" style="display: none;">
                            <li><a class="nav-link" href="#section8-sub1">8.1 循环神经网络入门</a></li>
                            <li><a class="nav-link" href="#section8-sub2">8.2 RNN 详解</a></li>
                            <li><a class="nav-link" href="#section8-sub3">8.3 长短期记忆网络</a></li>
                            <li><a class="nav-link" href="#section8-sub4">8.4 GRU 网络</a></li>
                            <li><a class="nav-link" href="#section8-sub5">8.5 WMT 数据集</a></li>
                            <li><a class="nav-link" href="#section8-sub6">8.6 RNN 翻译</a></li>
                            <li><a class="nav-link" href="#section8-sub7">8.7 Seq2Seq 论文</a></li>
                            <li><a class="nav-link" href="#section8-sub8">8.7 Word2Vec</a></li>
                        </ul>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#section9" onclick="toggleChildChapters(event, 'chapter9')">09 Transformer 架构</a>
                        <ul id="chapter8" class="child-chapters" style="display: none;">
                            <li><a class="nav-link" href="#section9-sub1">9.1 注意力机制</a></li>
                            <li><a class="nav-link" href="#section9-sub2">9.2 机器翻译</a></li>
                            <li><a class="nav-link" href="#section9-sub3">9.3 局部注意力</a></li>
                            <li><a class="nav-link" href="#section9-sub4">9.4 Transformer 论文</a></li>
                            <li><a class="nav-link" href="#section9-sub5">9.5 Transformer 实现</a></li>
                            <li><a class="nav-link" href="#section9-sub6">9.6 Transformer 注释</a></li>
                            <li><a class="nav-link" href="#section9-sub7">9.7 Keras 示例</a></li>
                        </ul>
                    </li>

                    <li class="nav-item">
                        <a class="nav-link" href="#section10" onclick="toggleChildChapters(event, 'chapter10')">10 生成式 (Generative)</a>
                        <ul id="chapter11" class="child-chapters" style="display: none;">
                            <li><a class="nav-link" href="#section10-sub1">10.1 自动编码器</a></li>
                            <li><a class="nav-link" href="#section10-sub2">10.2 神经风格迁移</a></li>
                            <li><a class="nav-link" href="#section10-sub3">10.3 DeepDream</a></li>
                            <li><a class="nav-link" href="#section10-sub4">10.4 生成对抗网络</a></li>
                            <li><a class="nav-link" href="#section10-sub5">10.5 Pix2Pix</a></li>
                            <li><a class="nav-link" href="#section10-sub6">10.6 CycleGAN</a></li>
                        </ul>
                    </li>

                    <li class="nav-item">
                        <a class="nav-link" href="#section11" onclick="toggleChildChapters(event, 'chapter11')">11 图片扩散 (Diffusion)</a>
                        <ul id="chapter11" class="child-chapters" style="display: none;">
                            <li><a class="nav-link" href="#section11-sub1">11.1 马尔可夫算法</a></li>
                            <li><a class="nav-link" href="#section11-sub2">11.2 热力学模型</a></li>
                            <li><a class="nav-link" href="#section11-sub3">11.3 去噪扩散模型</a></li>
                            <li><a class="nav-link" href="#section11-sub4">11.4 贝叶斯</a></li>
                            <li><a class="nav-link" href="#section11-sub5">11.5 稳定扩散</a></li>
                            <li><a class="nav-link" href="#section11-sub6">11.6 从头构建</a></li>
                        </ul>
                    </li>

                    <li class="nav-item">
                        <a class="nav-link" href="#section12" onclick="toggleChildChapters(event, 'chapter12')">12 大语言模型 (LLM)</a>
                        <ul id="chapter12" class="child-chapters" style="display: none;">
                            <li><a class="nav-link" href="#section12-sub1">12.1 nanoGPT</a></li>
                            <li><a class="nav-link" href="#section12-sub2">12.2 Llama 模型</a></li>
                            <li><a class="nav-link" href="#section12-sub3">12.3 BERT</a></li>
                        </ul>
                    </li>
                </ul>
            </nav>

            <!-- 中间内容 -->
            <main class="col-md-8">
                <h1>深度学习综合指南</h1>

                <p>这是一本面向初学者的深度学习综合指南。编写过程中借鉴了大量的经典教材、论文、文章，包括使用 AI 生成许多代码片段。教程主要分为四个阶段：</p>
                <ul>
                    <li>
                        <div class="title">第 1 - 4 章：数学与深度学习基础</div>
                        <p>复习数学知识（函数、线性代数、统计学、微积分）。使用 Keras 高级 API 快速实现分类问题，理解什么是深度学习，包括数据、前向传播、反向传播、神经元、神经网络、优化器、损失函数、激活函数、梯度下降等基础概念。</p>
                    </li>
                    <li>
                        <div class="title">第 5 - 6 章： 机器学习框架入门</div>
                        <p>系统学习主流机器学习框架 TensorFlow、PyTorch 和 JAX，熟练使用张量和自动微分，加载简单数据集并完成训练，理解这些框架的相似性与差异，为后续实践打下扎实基础。</p>
                    </li>
                    <li>
                        <div class="title">第 7 - 9 章： 经典网络与理论提升</div>
                        <p>通过翻译经典论文的方式，介绍三大深度学习网络：卷积神经网络、循环神经网络、注意力机制。深度学习的发展是循序渐进的，论文可以清晰地看到人们是如何思考，并解决实际问题的。</p>
                    </li>
                    <li>
                        <div class="title">第 10 - 12 章：实际应用与前沿探索</div>
                        <p>聚焦深度学习在文本、图片和语音生成中的实际应用，介绍稳定扩散、生成对抗网络等技术。探索大模型的简单实现，并详细解析 Llama 模型的运行与关键原理。</p>
                    </li>
                </ul>
                <p>文本以清晰简洁的风格编写，使其成为任何有兴趣学习深度学习的人的理想资源。</p>

                <section id="section1" class="content-section">
                    <h2>01 认识机器学习：绘制直线</h2>
                    <p>本章将回顾函数的基本概念，包括线性函数、多项式函数、幂函数、指数函数、有理函数、对数函数、三角函数，以及函数组合、函数变换、反函数等基本性质。</p>
                    <p>详细介绍 NumPy 科学计算库，使用各种方法创建 ndarray 数组，对数组进行索引和切片，并探讨数组之间的计算，例如广播、连接、乘法等运算。</p>
                    <p>使用传统解法和机器学习解法，求一条通过 100 个随机分布点的最佳拟合直线，即找到一条直线 \(y = m \cdot x + b\) 使得所有的点到直线的垂直距离之和（或平方和）最小。</p>

                    <h3 id="section1-sub1" class="content-section-sub">1.1 函数基础</h3>
                    <p>这是章节 1 的子标题 1 内容。</p>

                    <h3 id="section1-sub2" class="content-section-sub">1.2 NumPy 介绍</h3>
                    <p>这是章节 1 的子标题 2 内容。</p>

                    <h3 id="section1-sub3" class="content-section-sub">1.3 常见函数</h3>
                    <p>这是章节 1 的子标题 3 内容。</p>


                    <h3 id="section1-sub4" class="content-section-sub">1.4 传统方程求解</h3>
                    <p>这是章节 1 的子标题 4 内容。</p>


                    <h3 id="section1-sub5">1.5 机器学习求解</h3>
                    <p>这是章节 1 的子标题 5 内容。</p>

                </section>
                <section id="section2" class="content-section">
                    <h2>02 深度学习原理</h2>
                    
                    <p>了解机器学习与传统编程的区别，理解深度学习原理，熟悉人工神经网络的训练过程，包括数据预处理、神经元、权重、损失函数、优化器、反向传播等概念。</p>
                    <p>教材《线性代数介绍》深入浅出地介绍了线性代数的核心概念，包括矩阵运算、向量空间、线性变换、正交性、特征值与特征向量等。</p>
                    <p>将日常生活中的常见表示（特征数据、文字、图片、视频、声音）转换为神经网络的数据输入，对数据进行一些预处理操作，手动实现常见的数据处理算法。</p>

                    <h3 id="section2-sub1">2.1 什么是机器学习</h3>
                    <p>这是章节 2 的子标题 1 内容。</p>
                    
                    <h3 id="section2-sub2">2.2 人工神经网络</h3>
                    <p>这是章节 2 的子标题 2 内容。</p>

                    <h3 id="section2-sub3">2.3 线性代数</h3>
                    <h3 id="section2-sub4">2.4 数据表示</h3>
                    <h3 id="section2-sub5">2.5 数据操作</h3>
                    <h3 id="section2-sub6">2.6 常见微型数据集</h3>
                </section>
                <section id="section3" class="content-section">
                    <h2>03 分类问题：Keras 求解</h2>
                    
                    <p>介绍统计学的基础知识，包括采样、数据统计、概率、正态分布等。使用标准正态函数，生成分类问题的随机分布点。</p>
                    <p>二分类问题是指在机器学习或统计学中，将数据划分为两个类别的分类任务。常见的二分类问题包括垃圾邮件分类（垃圾邮件与正常邮件）、疾病诊断（有病与无病）、图像分类（有目标与无目标）等。</p>
                    <p>多分类问题是机器学习中的一个常见任务，其目标是将输入数据分配到多个类别中的一个。例如给定一张图片，模型需要判断图片中的内容是猫、狗还是鸟。</p>
                    <p>本章主要使用 Keras 高级 API 来解决以上两个问题，进一步熟悉深度学习中常见的模块，包括模型、层、损失函数、优化器等。通过快速上手简单的示例，理解深度学习全流程，为后续详细介绍奠定基础。</p>
                    
                    <h3 id="section3-sub1">3.1 统计学入门</h3>
                    <p>这是章节 3 的子标题 1 内容。</p>
                    <h3 id="section3-sub2">3.2 二分类问题</h3>
                    <p>这是章节 3 的子标题 2 内容。</p>
                    <h3 id="section3-sub3">3.3 Keras 快速入门</h3>
                    <p>这是章节 3 的子标题 3 内容。</p>
                    <h3 id="section3-sub4">3.4 图片分类</h3>
                    <h3 id="section3-sub5">3.5 其它分类问题</h3>
                </section>
                <section id="section4" class="content-section">
                    <h2>04 详解反向传播算法</h2>
                    
                    <p>复习导数（求微分）、链式法则、极值、偏导数等数学概念。通过 numpy 实现常见的激活函数和损失函数，并求解它们的导数。使用链式法则求解模型的梯度，理解权重是如何更新的。</p>
                    <p>手写 全连接神经网络 (Dense Neural Network, DNN) ，理解网络的训练过程，即求复合函数 h(g(f(weights, biases))) 的极值（极大或极小），实现几个简单的模型。</p>

                    <h3 id="section4-sub1" class="content-section-sub">
                        <a href="derivative.html" style="color: inherit;">4.1 导数</a>
                    </h3>

                    <h3 id="section4-sub2" class="content-section-sub">
                        <a href="#" style="color: inherit;">4.2 激活函数</a>
                    </h3>

                    <h3 id="section4-sub3" class="content-section-sub">
                        <a href="#" style="color: inherit;">4.3 损失函数</a>
                    </h3>

                    <h3 id="section4-sub4" class="content-section-sub">
                        <a href="#" style="color: inherit;">4.4 梯度下降</a>
                    </h3>

                    <h3 id="section4-sub5" class="content-section-sub">
                        <a href="neural_network_intro.html" style="color: inherit;">4.5 手写神经网络</a>
                    </h3>
                    <p>翻译文章 <a href="https://victorzhou.com/blog/intro-to-neural-networks/">Machine Learning for Beginners: An Introduction to Neural Networks</a> ，没有其它改动。</p>

                    <h3 id="section4-sub6" class="content-section-sub">
                        <a href="#" style="color: inherit;">4.6 绘制曲线</a>
                    </h3>

                    <h3 id="section4-sub7" class="content-section-sub">
                        <a href="#" style="color: inherit;">4.7 坐标点分类</a>
                    </h3>
                </section>
                <section id="section5" class="content-section">
                    <h2>05 张量和自动微分</h2>
                    
                    <h3 id="section5-sub1" class="content-section-sub">
                        <a href="#" style="color: inherit;">5.1 快速预览</a>
                    </h3>
                    <h3 id="section5-sub2" class="content-section-sub">
                        <a href="#" style="color: inherit;">5.2 张量表示</a>
                    </h3>
                    <h3 id="section5-sub3" class="content-section-sub">
                        <a href="#" style="color: inherit;">5.3 自动微分</a>
                    </h3>
                    <h3 id="section5-sub4" class="content-section-sub">
                        <a href="#" style="color: inherit;">5.4 micrograd</a>
                    </h3>
                    <h3 id="section5-sub5" class="content-section-sub">
                        <a href="#" style="color: inherit;">5.5 tinygrad 分析</a>
                    </h3>
                </section>

                <section id="section6" class="content-section">
                    <h2>06 训练神经网络</h2>

                    <p>使用 TensorFlow / PyTorch / JAX 进行训练，熟练使用主流机器学习库。介绍如何对训练过程进行优化。</p>

                    <h3 id="section6-sub1" class="content-section-sub">
                        <a href="#" style="color: inherit;">6.1 NumPy</a>
                    </h3>

                    <h3 id="section6-sub2" class="content-section-sub">
                        <a href="#" style="color: inherit;">6.2 TensorFlow</a>
                    </h3>

                    <h3 id="section6-sub3" class="content-section-sub">
                        <a href="#" style="color: inherit;">6.3 PyTorch</a>
                    </h3>

                    <h3 id="section6-sub4" class="content-section-sub">
                        <a href="#" style="color: inherit;">6.4 JAX</a>
                    </h3>
                </section>

                <section id="section7" class="content-section">
                    <h2>07 卷积神经网络</h2>

                    <h3 id="section7-sub1" class="content-section-sub">
                        <a href="#" style="color: inherit;">7.1 认识卷积网络</a>
                    </h3>

                    <h3 id="section7-sub2" class="content-section-sub">
                        <a href="#" style="color: inherit;">7.2 手写卷积网络</a>
                    </h3>

                    <h3 id="section7-sub3" class="content-section-sub">
                        <a href="#" style="color: inherit;">7.3 AlexNet 论文</a>
                    </h3>

                    <h3 id="section7-sub4" class="content-section-sub">
                        <a href="#" style="color: inherit;">7.4 U-Net 论文</a>
                    </h3>
                    <p>翻译论文 <a href="https://arxiv.org/abs/1505.04597">U-Net: Convolutional Networks for Biomedical Image Segmentation</a></p>

                    <h3 id="section7-sub5" class="content-section-sub">
                        <a href="resnet_paper.html" style="color: inherit;">7.5 ResNet 论文</a>
                    </h3>
                    <p>翻译论文 <a href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a></p>
    
                </section>

                
                <section id="section8" class="content-section">
                    <h2>08 循环神经网络</h2>
                    <p><strong>循环神经网络 (Recurrent Neural Network, RNN)</strong> 是一种用于处理序列数据的神经网络架构，与传统的前馈神经网络不同，RNN 在每一时刻的输出不仅依赖当前输入，还依赖于前一时刻的隐藏状态，从而能够捕捉序列中的时间依赖关系。</p>

                    <h3 id="section8-sub1" class="content-section-sub">
                        <a href="recurrent_network_intro.html" style="color: inherit;">8.1 循环神经网络入门</a>
                    </h3>
                    <p>翻译文章 <a href="https://victorzhou.com/blog/intro-to-rnns/">An Introduction to Recurrent Neural Networks for Beginners</a>，主要有以下几点区别：</p>
                    <ul>
                        <li>
                            <p>1. 在梯度计算阶段增加更加详细解释，推导 softmax 函数的导数。</p>
                        </li>
                        <li>
                            <p>2. 增加 8.1.9 小节 使用 PyTorch 实现这个简单的示例。</p>
                        </li>
                    </ul>

                    <h3 id="section8-sub2" class="content-section-sub">
                        <a href="recurrent_detail.html" style="color: inherit;">8.2 RNN 详解</a>
                    </h3>

                    <p>翻译系列文章：</p>
                    <ul>
                        <li>
                            <p><a href="https://dennybritz.com/posts/wildml/recurrent-neural-networks-tutorial-part-1/">Recurrent Neural Networks Tutorial, Part 1 – Introduction to RNNs</a></p>
                        </li>
                        <li>
                            <p><a href="https://dennybritz.com/posts/wildml/recurrent-neural-networks-tutorial-part-2/">Recurrent Neural Networks Tutorial, Part 2 – Implementing a RNN with Python, Numpy and Theano</a></p>
                        </li>
                        <li>
                            <p><a href="https://dennybritz.com/posts/wildml/recurrent-neural-networks-tutorial-part-3/">Recurrent Neural Networks Tutorial, Part 3 – Backpropagation Through Time and Vanishing Gradients</a></p>
                        </li>
                        <li>
                            <p><a href="https://dennybritz.com/posts/wildml/recurrent-neural-networks-tutorial-part-4/">Recurrent Neural Networks Tutorial, Part 4 – Implementing a GRU and LSTM RNN with Python and Theano</a></p>
                        </li>
                    </ul>
                    <p>主要有如下区别：</p>
                    <ul>
                        <li>
                            <p>删除过时的 Theano 机器学习库部分，采用流行的 PyTorch 实现。</p>
                        </li>
                    </ul>

                    <h3 id="section8-sub3" class="content-section-sub">
                        <a href="#" style="color: inherit;">8.3 长短期记忆网络</a>
                    </h3>

                    <p>翻译论文 <a href="https://deeplearning.cs.cmu.edu/S23/document/readings/LSTM.pdf">Long Short-Term Memory</a></p>

                    <h3 id="section8-sub4" class="content-section-sub">
                        <a href="#" style="color: inherit;">8.4 GRU 网络</a>
                    </h3>

                    <p>翻译论文 <a href="https://arxiv.org/pdf/1412.3555">Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling</a></p>

                    <h3 id="section8-sub5" class="content-section-sub">
                        <a href="wmt_dataset.html" style="color: inherit;">8.5 WMT 数据集</a>
                    </h3>

                    <p>处理欧洲议会会议记录 (Europarl) 第 7 版中英语-德语、英语-法语翻译数据集，使用 BLEU 方法进行评估。</p>
                    <p>翻译论文 <a href="https://aclanthology.org/P02-1040.pdf">BLEU: a Method for Automatic Evaluation of Macine Translation</a></p>

                    <h3 id="section8-sub6" class="content-section-sub">
                        <a href="rnn_translate.html" style="color: inherit;">8.6 RNN 翻译</a>
                    </h3>

                    <p>参考 GitHub 网站的 <a href="https://github.com/bentrevett/pytorch-seq2seq">pytorch-seq2seq</a> 仓库，引用以下几篇论文：</p>

                    <ul>
                        <li>
                            <p><a href="https://arxiv.org/abs/1409.3215">Sequence to Sequence Learning with Neural Networks</a></p>
                        </li>
                        <li>
                            <p><a href="https://arxiv.org/abs/1406.1078">Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation</a></p>
                        </li>
                        <li>
                            <p><a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a></p>
                        </li>
                    </ul>
                    <p>使用 PyTorch 和 TorchText 实现一些序列到序列 (seq2seq) 模型的教程。</p>

                    <h3 id="section8-sub7" class="content-section-sub">
                        <a href="seq2seq_paper.html" style="color: inherit;">8.7 Seq2Seq 论文</a>
                    </h3>
                    <p>翻译论文 <a href="https://arxiv.org/abs/1409.3215">Sequence to Sequence Learning with Neural Networks</a></p>

                    <h3 id="section8-sub8" class="content-section-sub">
                        <a href="#" style="color: inherit;">8.8 Word2Vec 论文</a>
                    </h3>
                    <p>翻译论文 <a href="https://arxiv.org/abs/1301.3781">Efficient Estimation of Word Representations in Vector Space</a></p>

                </section>
                <section id="section9" class="content-section">
                    <h2>09 Transformer 架构</h2>

                    <h3 id="section9-sub1" class="content-section-sub">
                        <a href="attention_mechanism.html" style="color: inherit;">9.1 注意力机制</a>
                    </h3>
                    <p>采用教材《动手学深度学习》<a href="https://zh.d2l.ai/chapter_attention-mechanisms/index.html">第 10 章 注意力机制</a> </p>

                    <h3 id="section9-sub2" class="content-section-sub">
                        <a href="#" style="color: inherit;">9.2 机器翻译论文</a>
                    </h3>
                    <p>翻译论文 <a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a></p>

                    <h3 id="section9-sub3" class="content-section-sub">
                        <a href="#" style="color: inherit;">9.3 注意力论文</a>
                    </h3>
                    <p>翻译论文 <a href="https://arxiv.org/abs/1508.04025">Effective Approaches to Attention-based Neural Machine Translation</a></p>

                    <h3 id="section9-sub4" class="content-section-sub">
                        <a href="transformer_paper.html" style="color: inherit;">9.4 Transformer 论文</a>
                    </h3>
                    <p>翻译论文 <a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a></p>

                    <h3 id="section9-sub5">9.5 Transformer 实现</h3>


                    <h3 id="section9-sub6">9.6 Transformer 注释</h3>

                    <p>翻译文章 <a href="https://nlp.seas.harvard.edu/annotated-transformer/">The Annotated Transformer</a></p>

                    <h3 id="section9-sub7">9.7 Keras 示例</h3>
                </section>

                <section id="section10" class="content-section">
                    <h2>生成式 (Generative)</h2>
                    <p>生成式方法的目标是在已知的样本数据上学习其特征分布，然后生成具有相似特征的全新数据，包括：稳定扩撒、神经风格迁移、DeepDream、卷积生成对抗网络、Pix2Pix 、CycleGAN 。</p>

                    <h3 id="section10-sub1">10.1 自动编码器</h3>

                    <h3 id="section10-sub2" class="content-section-sub">
                        <a href="#" style="color: inherit;">10.2 神经风格迁移</a>
                    </h3>

                    <h3 id="section10-sub3" class="content-section-sub">
                        <a href="#" style="color: inherit;">10.3 DeepDream</a>
                    </h3>

                    <h3 id="section10-sub5" class="content-section-sub">
                        <a href="#" style="color: inherit;">10.4 生成对抗网络</a>
                    </h3>
                    <p>生成对抗网络 (Generative Adversarial Networks, GANs) 通过对抗过程训练两个网络，生成器 (Generator) 学习创建看起来真实的图像，而鉴别器 (Discriminator) 学习区分真实图像和假图像。</p>

                    <h3 id="section10-sub5" class="content-section-sub">
                        <a href="#" style="color: inherit;">10.5 Pix2Pix</a>
                    </h3>

                    <h3 id="section10-sub6" class="content-section-sub">
                        <a href="#" style="color: inherit;">10.6 CycleGAN</a>
                    </h3>
                </section>

                <section id="section11" class="content-section">
                    <h2>图片扩散 (Diffusion)</h2>
                    <p>这是章节 4 的内容。欢迎补充更多章节。</p>
                    <h3 id="section11-sub1" class="content-section-sub">
                        <a href="#" style="color: inherit;">11.1 马尔可夫算法</a>
                    </h3>
                    <h3 id="section11-sub2" class="content-section-sub">
                        <a href="#" style="color: inherit;">11.2 热力学过程</a>
                    </h3>
                    <h3 id="section11-sub3" class="content-section-sub">
                        <a href="#" style="color: inherit;">11.3 去噪扩散模型</a>
                    </h3>
                    <h3 id="section11-sub4" class="content-section-sub">
                        <a href="#" style="color: inherit;">11.4 贝叶斯</a>
                    </h3>
                    <h3 id="section11-sub5" class="content-section-sub">
                        <a href="#" style="color: inherit;">11.5 稳定扩散</a>
                    </h3>
                    <h3 id="section11-sub6" class="content-section-sub">
                        <a href="#" style="color: inherit;">11.6 从头构建</a>
                    </h3>
                </section>

                <section id="section12" class="content-section">
                    <h2>大语言模型 (LLM)</h2>
                    <p>nanoGPT 是最简单、最快的中型 GPT 训练/微调存储库，优先考虑实用性而非教育性。介绍 Llama 开源模型，包括如何访问模型、托管、操作方法和集成指南。</p>
                    <h3 id="section12-sub1" class="content-section-sub">
                        <a href="#" style="color: inherit;">12.1 nanoGPT</a>
                    </h3>
                    <h3 id="section12-sub2" class="content-section-sub">
                        <a href="#" style="color: inherit;">12.2 Llama 模型</a>
                    </h3>
                    <h3 id="section12-sub3" class="content-section-sub">
                        <a href="#" style="color: inherit;">12.3 BERT</a>
                    </h3>
                </section>
            </main>

            <!-- 右侧小标题导航 -->
            <aside class="col-md-2 right-sidebar">
                <!-- <h5>标题</h5>
                <ul id="dynamic-sidebar" class="nav flex-column"> -->
                    <!-- 动态内容 -->
                <!-- </ul> -->
            </aside>
        </div>
    </div>

    <!-- 引入 Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>

    <script type="text/javascript" async
            src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>

    <script>
        function toggleChildChapters(event, chapterId) {
            event.preventDefault();
            const chapter = document.getElementById(chapterId);
            if (chapter.style.display === "none" || !chapter.style.display) {
                chapter.style.display = "block";
            } else {
                chapter.style.display = "none";
            }
        }
    </script>
    <script>
        // 更新右侧导航，显示当前h3的小节
        function updateRightSidebar(currentH3Id) {
            const sidebar = document.getElementById("dynamic-sidebar");
            sidebar.innerHTML = ""; // 清空当前内容

            // 查找当前h3下的所有h4元素
            const h3Element = document.getElementById(currentH3Id);
            let nextSibling = h3Element.nextElementSibling;
            const h4Elements = [];

            // 获取所有h4标签，直到遇到下一个h3标签
            while (nextSibling && nextSibling.tagName !== "H3") {
                if (nextSibling.tagName === "H4") {
                    h4Elements.push(nextSibling);
                }
                nextSibling = nextSibling.nextElementSibling;
            }

            // 为每个h4元素创建导航项
            h4Elements.forEach(h4 => {
                const li = document.createElement("li");
                li.className = "nav-item";
                li.innerHTML = `<a class="nav-link" href="#${h4.id}" data-id="${h4.id}">${h4.innerText}</a>`;
                sidebar.appendChild(li);
            });

            // 默认高亮第一个小节
            if (h4Elements.length > 0) {
                highlightActiveSubtitle(h4Elements[0].id);
            }
        }

        // 高亮当前h4小节
        function highlightActiveSubtitle(subtitleId) {
            const links = document.querySelectorAll("#dynamic-sidebar a");
            links.forEach(link => {
                if (link.getAttribute("data-id") === subtitleId) {
                    link.classList.add("active");
                } else {
                    link.classList.remove("active");
                }
            });
        }

        // 监听h3小节滚动，显示对应的h4小节
        const observer = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    const currentH3Id = entry.target.id;
                    updateRightSidebar(currentH3Id);
                }
            });
        }, {
            threshold: 0.5 // 当h3元素有一半进入视口时触发
        });

        // 观察所有h3元素
        const h3Elements = document.querySelectorAll("h3");
        h3Elements.forEach(h3 => {
            observer.observe(h3);
        });
    </script>
</body>
</html>
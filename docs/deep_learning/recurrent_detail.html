<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>循环神经网络入门</title>
    <!-- 引入 Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        .sidebar {
            position: sticky;
            top: 0;
            height: 100vh;
            overflow-y: auto;
            background-color: #f8f9fa;
            color: #000;
            border-right: 1px solid #ddd;
        }

        .custom-title {
            font-size: 2.5rem;
            font-weight: 700;
            color: #4caf50;
            text-align: center;
            margin-bottom: 20px;
            border-bottom: 3px solid #4caf50; /* 标题下边框 */
        }

        .title-subtext {
            font-size: 1.2rem;
            color: #6c757d; /* Bootstrap 灰色 */
            text-align: center;
        }
        body {
            font-family: 'Arial', sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background: #f4f4f9;
            color: #333;
        }
        .content {
            padding: 20px;
            background: #fff;
            border-radius: 8px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }
        .content h2 {
            width: 100%;
            font-size: 3rem;
            line-height: 1.6;
            color: #4caf50;
            text-align: center;
            margin-bottom: 40px;
            border-bottom: 3px solid #4caf50;
            display: inline-block;
            padding-bottom: 10px;
            font-weight: bold;
            text-shadow: 1px 1px 5px rgba(0, 0, 0, 0.1);
        }
        pre {
            background-color: #2d2d2d;
            color: #f8f8f2;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            font-size: 16px;
            line-height: 1.5;
        }
        .added {
            color: #10e6e2;
            display: inline-block;
            width: 100%;
        }
        code {
            font-family: "Courier New", Courier, monospace;
        }
        .content h3 {
            margin-top: 60px;
            color: #8e44ad;
        }
        .content h4 {
            margin-top: 40px;
            color: #8e44ad;
        }
        .content p {
            font-size: 1.1em;
            margin: 20px 0;
        }
        .highlight-math {
            background-color: #FFCC99;
            padding: 5px;
            border-radius: 5px;
        }
        .highlight-link {
            color: #f39c12;
            font-weight: bold;
        }
        .highlight {
            background-color: #f1c40f;
            font-weight: bold;
        }
        pre {
            background: #263238;
            color: #c3e88d;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            margin: 20px 0;
            font-size: 0.9em;
        }
        ul {
            list-style: none;
            padding-left: 20px;
            margin: 10px 0;
        }
        .with-bullets {
            list-style: disc;
            padding-left: 10px;
            margin: 10px 0 10px 20px;
        }
        ul li {
            margin: 4px 0;
            color: #34495e;;
        }
        li .title {
            font-weight: bold;
            color: #2c3e50;
            font-size: 18px;
            margin-bottom: 6px;
        }
        li p {
            color: #34495e;
            font-size: 16px;
        }
        .right-sidebar {
            position: sticky;
            top: 0;
            height: 100vh;
            overflow-y: auto;
            padding: 20px;
            background-color: #f8f9fa;
            border-left: 1px solid #ddd;
        }
        .right-sidebar a {
            color: #343a40;
            text-decoration: none;
        }
        .right-sidebar a:hover {
            text-decoration: underline;
        }
        .right-sidebar .active {
            font-weight: bold;
            color: #007bff;
        }
        #dynamic-sidebar ul {
            list-style-type: none;
            padding-left: 0;
        }
        #dynamic-sidebar ul ul {
            padding-left: 20px;
        }
        a {
            text-decoration: underline;
            text-underline-offset: 4px;
            color: #3498db;
        }
        a:hover {
            color: #2c3e50;
        }
        img {
            display: block;
            margin: 0 auto;
            max-width: 100%;
            height: auto;
            border-radius: 10px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.15), 0 -2px 6px rgba(0, 0, 0, 0.1);;
        }
        .comment {
            color: #6c757d;
            font-size: 0.9em;
            font-style: italic;
            margin: 20px 0;
            border-left: 3px solid #d6d8db;
            padding-left: 10px;
        }
        table {
            width: 50%;
            border-collapse: collapse;
            margin: 20px auto;
            font-family: Arial, sans-serif;
        }
        th, td {
            border: 1px solid #ccc;
            padding: 10px;
            text-align: center;
        }
        th {
            background-color: #f4f4f4;
        }
        .positive {
            color: green;
            font-weight: bold;
        }
        .negative {
            color: red;
            font-weight: bold;
        }
    </style>
</head>
<body>
    <div class="container-fluid">
        <div class="row">
        <!-- 左侧小节列表 -->
        <nav class="col-md-2 sidebar">

        </nav>

        <!-- 中间内容：显示具体某一个小节 -->
        <main class="col-md-8 content">
            <h2 class="custom-title">8.2 RNN 详解</h2>
            <p class="title-subtext">使用 PyTorch 构建语言生成模型，实现 GRU/LSTM RNN 网络！</p>
            <p style="color: #a0a0a0;">创建日期: 2025-01-20</p>
            <p>循环神经网络（RNN）是一种流行的模型，在许多 NLP 任务中都表现出了巨大的潜力。但尽管它们最近很受欢迎，但我只找到了有限数量的资源来彻底解释 RNN 的工作原理以及如何实现它们。这就是本教程的内容，它由多个部分组成的系列，我计划在其中介绍以下内容：</p>
            <ul>
                <li>
                    <p>1. RNN 介绍</p>
                </li>
                <li>
                    <p>2. 使用 Python 和 PyTorch 实现 RNN</p>
                </li>
                <li>
                    <p>3. 理解时间反向传播 (BPTT) 算法和梯度消失问题</p>
                </li>
                <li>
                    <p>4. 实现 GRU/LSTM RNN 网络</p>
                </li>
            </ul>

            <p>作为本教程的一部分，我们将实现一个基于循环神经网络的语言模型。语言模型的应用有两个方面：首先，它允许我们根据句子在现实世界中出现的可能性对任意句子进行评分。这为我们提供了语法和语义正确性的衡量标准。此类模型通常用作机器翻译系统的一部分。其次，语言模型允许我们生成新文本（我认为这是更酷的应用）。在莎士比亚数据集上训练语言模型使我们能够生成类似莎士比亚的文本。</p>
            <p>我假设你对基础神经网络有所了解。如果不熟悉，可以去阅读 <a href="index.html#section2">第 02 章 深度学习原理</a> 的内容，它将指导我们了解非循环网络背后的思想和实现。</p>
        
            <h3>8.2.1 RNN 介绍</h3>

            <p>简单地介绍 RNN 是什么，常见的 RNN 结构，以及有哪些用途。</p>

            <h4>8.2.1.1 什么是 RNN</h4>
            <p>RNN 背后的想法是利用顺序信息，在传统的神经网络中，我们假设所有的输入（和输出）都是相互独立的。但对于许多任务来说，这是一个坏主意，如果你想预测句子中的下一个单词，你最好知道它之前有哪些单词。</p>
            <p>RNN 之所以被称为“循环”，是因为它们对序列的每个元素执行相同的任务，而输出取决于之前的计算。另一种思考 RNN 的方式是，它们有一个“记忆”，可以捕获已经被计算的信息。理论上，RNN 可以利用任意长度序列中的信息，但实际上它们仅限于回顾固定的数量（稍后会详细解释）。典型的 RNN 如下所示：</p>
            <img src="rnn_unfold.jpg" alt="RNN 展开">
            <p>上图显示了一个正在被展开的 RNN 网络。展开的意思是我们将整个序列的网络写出来。假设我们关心的序列是一个包含 5 个单词的句子，则网络将展开为 5 层，每个单词一层。控制 RNN 中发生计算的公式如下：</p>
            <ul class="with-bullets">
                <li>
                    <p>\(x_t\) 是在步骤 \(t\) 时刻的输入。比如，\(x_1\) 是句子中第二个单词的独热向量。</p>
                </li>
                <li>
                    <p>\(s_t\) 是在步骤 \(t\) 时刻的隐藏状态，相当于网络的记忆。\(s_t\) 的计算基于之前的隐藏状态和当前步骤的输入：\(s_t = f(U \cdot x_t + W \cdot s_{t-1})\) 。函数 f 通常是非线性的 tanh 或者 ReLU 激活函数。\(s_{-1}\) 用于计算第一个隐藏状态，通常所有数值初始化为零。</p>
                </li>
                <li>
                    <p>\(o_t\) 对应步骤 \(t\) 时刻的输出，比如我们想要预测句子中的下一个单词，它将是我们词汇表中的概率向量，\(o_t = softmax(V \cdot s_t)\) 。</p>
                </li>
            </ul>
            <p>有几点需要注意的是：</p>
            <ul class="with-bullets">
                <li>
                    <p>我们可以认为隐藏状态 \(s_t\) 是网络的记忆，\(s_t\) 捕获有关之前所有时间步骤中发生的信息。输出 \(o_t\) 仅根据当时的记忆 \(s_t\) 来计算。正如前面说到的，现实情况会更复杂些，因为 \(s_t\) 不能获取太久之前步骤的信息。</p>
                </li>
                <li>
                    <p>与在每一层使用不同的参数的传统深度神经网络不同，在所有步骤中，RNN 共享相同的参数 \((U, V, W)\) 。这反映了我们在每个步骤中执行的相同的任务，只是输入不同。这大大减少我们需要学习的参数总量。</p>
                </li>
                <li>
                    <p>上图在每个时间步骤都有输出，但根据任务的不同，这可能不是必需的。例如在预测句子的情绪时，我们可能只关心最终输出，而不是每个单词后的情绪。同样，我们可能不需要每个时间步骤的输入。RNN 的主要特征是其隐藏状态，它捕获序列的一些信息。</p>
                </li>
            </ul>

            <h4>8.2.1.2 能做什么</h4>
            <p>RNN 在许多 NLP 任务中都取得了巨大成功，现在我应该提到，最常用的 RNN 类型是 LSTM ，它在捕获长期依赖性方面比普通 RNN 好得多。但别担心，LSTM 本质上与我们将在本教程中开发的 RNN 相同，只是它们计算隐藏状态的方式不同。我们将在后面的小节中更详细地介绍 LSTM。以下是 RNN 在 NLP 领域的一些示例应用，这绝不是一份详尽的清单。</p>
            <p><strong>语言建模和生成文本</strong></p>
            <p>给定一个单词序列，我们想要根据之前已经给定的单词预测每个单词的概率。语言模型是我们能够衡量句子的相似度，这是机器翻译的重要输入（高相似度的句子通常是正确的）。能够预测下一个单词的副作用是我们得到了一个生成模型，它使我们能够通过从输出概率中采样，来生成新文本。并且根据我们的训练数据，可以生成各种各样的东西。在语言建模中，我们的输入通常是单词序列（例如编码为独热向量），我们的输出是预测单词的序列。在训练网络时，设置 \(o_t = x_{t+1}\) ，因为我们想 \(t\) 时刻的输出将是下个单词。</p>
            <p><strong>机器翻译</strong></p>
            <p>机器翻译与语言建模类似，因为我们的输入是源语言（例如德语）中的单词序列。我们希望输出是目标语言（例如英语）中的单词序列。一个关键的区别是，我们的输出只有在我们看到完整的输入后才开始，因为我们翻译的句子的第一个单词可能需要从完整的输入序列中捕获信息。</p>
            <p>以下是关于机器翻译的研究论文：</p>
            <p><strong>语音识别</strong></p>
            <p>给定来自声波信号作为输入序列，我们可以预测一系列语音片段及其概率。</p>
            <p><strong>生成图像描述</strong></p>
            <p>RNN 与卷积神经网络一起被用作模型的一部分，用于生成未标记图像的描述。这种方法的效果非常惊人。组合模型甚至将生成的单词与图像中的特征进行对齐。</p>

            <h4>8.2.1.3 训练 RNN</h4>
            <p>训练 RNN 与训练传统神经网络类似。我们也使用反向传播算法，但略有不同。由于网络中的所有时间步骤共享参数，因此每个输出处的梯度不仅取决于当前时间步骤的计算，还取决于先前的时间步骤。例如想要计算时刻 \(t = 4\) 的梯度，我们需要反向传播 3 个时刻，并将这些梯度加起来。这叫做 时间上的反向传播 (BPTT) 。如果这还不太清除，别担心，我么后续会介绍细节。现在，只需注意这样一个试试：使用 BPTT 训练的普通 RNN 难以学习长期依赖关系（例如相聚很远的步骤之间的依赖关系），这是由于所谓的梯度消失或爆炸引起的。存在一些机制来处理这些问题，某些类型的 RNN（如 LSTM）是专门为解决该问题而设计的。</p>

            <h4>8.2.1.4 RNN 拓展</h4>
            <p>多年来，研究人员开发了更复杂的 RNN 类型来处理普通 RNN 模型的一些缺点。我们将在后续文章中更详细地介绍它们，但我希望本节作为简要概述，以便您熟悉模型的分类。</p>
            <p><strong>双向 RNN</strong></p>
            <p>基于以下的思想：时刻 t 的输出可能不仅取决于序列中的前一个元素，还取决于未来的元素。例如，要预测序列中缺失的单词，您需要同时查看左侧和右侧上下文。双向 RNN 非常简单。它们只是两个堆叠在一起的 RNN。然后根据两个 RNN 的隐藏状态计算输出。</p>
            <p><strong>LSTM 网络</strong></p>
            <p>如今非常流行，我们在上面简要介绍了它们。LSTM 的架构与 RNN 并无根本区别，但它们使用不同的函数来计算隐藏状态。LSTM 中的记忆称为单元，我们可以将它想象成为一个黑盒子，将之前的状态 \(h_{t-1}\) 和当前的输入 \(x_t\) 作为输入。单元内部决定哪些记忆被保留，哪些被擦除。它们然后结合之前的状态、当前的记忆、和输入产生输出。这些单元在在捕获长期依赖关系方面非常有效。</p>
        

            <h3>8.2.2 实现 RNN</h3>
            <h4>8.2.2.1 语言建模</h4>
            <h4>8.2.2.2 数据与预处理</h4>
            <h4>8.2.2.3 构建 RNN</h4>
            <h4>8.2.2.4 前向传播</h4>
            <h4>8.2.2.5 BPTT 梯度</h4>
            <h4>8.2.2.6 文本生成</h4>

        </main>

            <!-- 右侧小标题导航 -->
            <aside class="col-md-2 right-sidebar">
                <h5>标题</h5>
                <ul id="dynamic-sidebar" class="nav flex-column">
                    <!-- 动态内容 -->
                </ul>
            </aside>
        </div>
    </div>

        <!-- 引入 Bootstrap JS -->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>

        <script type="text/javascript" async
            src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>

        <script>
            // 获取所有的 h3 和 h4 元素
            const sidebar = document.getElementById('dynamic-sidebar');
            const elements = Array.from(document.querySelectorAll('h3, h4')); // 获取所有 h3 和 h4 元素

            // 动态生成目录项
            elements.forEach(element => {
                // 如果没有 id，则为该元素生成一个 id
                if (!element.id) {
                    element.id = `${element.tagName.toLowerCase()}-${Math.random().toString(36).substr(2, 9)}`;
                }

                const link = document.createElement('a');
                link.href = `#${element.id}`;
                link.textContent = element.textContent;

                const listItem = document.createElement('li');
                // 如果是 h4 元素，添加缩进
                if (element.tagName.toLowerCase() === 'h4') {
                    listItem.style.marginLeft = '20px'; // 控制缩进
                }
                listItem.appendChild(link);

                sidebar.appendChild(listItem);
            });

            // 高亮当前目录项
            function highlightCurrentLink(targetId) {
                const links = sidebar.querySelectorAll('a');
                links.forEach(link => {
                    if (link.getAttribute('href') === `#${targetId}`) {
                        link.classList.add('highlight-link');
                    } else {
                        link.classList.remove('highlight-link');
                    }
                });
            }

            // 页面滚动时更新高亮
            window.addEventListener('scroll', () => {
                let found = false;
                elements.forEach(el => {
                    const rect = el.getBoundingClientRect();
                    if (rect.top <= window.innerHeight / 2 && rect.bottom >= 0) {
                        if (!found) {
                            highlightCurrentLink(el.id);
                            found = true;
                        }
                    }
                });
            });

            // 为每个目录链接添加点击事件
            const links = sidebar.querySelectorAll('a');
            links.forEach(link => {
                link.addEventListener('click', (e) => {
                    e.preventDefault();
                    const targetId = link.getAttribute('href').substring(1);
                    const targetElement = document.getElementById(targetId);
                    if (targetElement) {
                        targetElement.scrollIntoView({ behavior: 'smooth' });
                        highlightCurrentLink(targetId);
                    }
                });
            });
        </script>
</body>
</html>
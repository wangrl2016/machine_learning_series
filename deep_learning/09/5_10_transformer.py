# 原语言的词汇表大小
src_vocab_size = 5000
# 目标语言的词汇表大小
tgt_vocab_size = 5000
# 嵌入维度
d_model = 512
# 多头注意力中的数量
num_heads = 8
# 前馈网络的层数
num_layers = 6
# 隐藏层的节点数量
d_ff = 2048
# 序列的最大长度
max_seq_length = 100
# 随机失活概率
dropout = 0.1

class Transformer(nn.Module):
    pass

if __name__ == '__main__':
    pass
